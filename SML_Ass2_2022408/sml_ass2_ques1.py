# -*- coding: utf-8 -*-
"""SML_Ass2_Ques1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tx3OwEZjHlXiXEEzgIvtLIvd1RpQsAlK
"""

import numpy as np
import math
import matplotlib.pyplot as plt
import tensorflow as tf

# Function to train the QDA model
def qda(train_images, train_labels, epsilon):
    global mean, class_matrix, count, log_cov_det, cov_inv

    # Initialize matrices and counts for each class
    class_matrix = []
    count = np.zeros(10, dtype=int)

    # Separate images by class
    for i in range(10):
        vector = [train_images[j] for j in range(len(train_images)) if train_labels[j] == i]
        count[i] = len(vector)
        class_matrix.append(vector)

    # Convert class matrices to numpy arrays
    class_matrix = [np.array(matrix) for matrix in class_matrix]

    # Vectorize the data
    classDataVect = [matrix.reshape(count[i], 784) for i, matrix in enumerate(class_matrix)]

    # Calculate the mean of each class
    mean = [np.mean(vect, axis=0) for vect in classDataVect]

    # Calculate the covariance matrix of each class
    cov = [np.cov(vect.T) + epsilon * np.identity(vect.shape[1]) for vect in classDataVect]

    # Calculate the determinant of each covariance matrix
    log_cov_det = [np.linalg.slogdet(cov_matrix)[1] for cov_matrix in cov]

    # Calculate the inverse of each covariance matrix
    cov_inv = [np.linalg.inv(cov_matrix) for cov_matrix in cov]

# Function to categorize test images
def categorise(test_images):
    # Vectorize the test image
    test_images = test_images.reshape(1, 784)

    # Calculate the probability of each class
    prob = [math.log(count[i]/len(train_images)) - 0.5 * log_cov_det[i] -
            0.5 * np.dot(np.dot((np.subtract(test_images, mean[i])), cov_inv[i]), (np.subtract(test_images, mean[i]).T))
            for i in range(10)]

    # Return the class with maximum probability
    return np.argmax(prob)

# Function to calculate accuracy
def accuracy(test_images, test_labels):
    count = [0]*10
    correct_count = [0]*10

    # Count the number of correct predictions for each class
    for i in range(len(test_images)):
        count[test_labels[i]] += 1
        if categorise(test_images[i]) == test_labels[i]:
            correct_count[test_labels[i]] += 1

    # Calculate and print the accuracy for each class
    print("Accuracy of each class")
    accuracy = []
    for i in range(10):
        acc = round((correct_count[i]/count[i])*100, 3)
        print(i, "-->",  acc, end=" %\n")
        accuracy.append(acc)

    # Calculate and print the overall accuracy
    overall_accuracy = round((sum(correct_count)/sum(count))*100,3)
    print("Overall Accuracy: ", overall_accuracy)

    return overall_accuracy, accuracy
#--------------------------------------------------------------------------------------------------#

# Load the MNIST dataset
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Plot the dataset
plt.figure(figsize=(12, 10))
for i in range(10):
    idxs = np.where(train_labels == i)[0][:5]
    for j, idx in enumerate(idxs):
        plt.subplot(10, 5, i * 5 + j + 1)
        plt.imshow(train_images[idx], cmap='Purples')
        plt.title(f'Class {i}')
        plt.axis('off')
plt.show()

# List of regularization parameters to test
epsilon_values = [10**-6, 10**-4, 10**-2, 0.1]

# Initialize a dictionary to store the accuracy for each epsilon
accuracy_dict = {}

# Loop over the epsilon values
for epsilon in epsilon_values:
    # Train the QDA model
    qda(train_images, train_labels, epsilon)

    # Calculate and print the accuracy
    overall_accuracy, _ = accuracy(test_images, test_labels)
    print(f"Overall accuracy for epsilon={epsilon}: {overall_accuracy}")

    # Store the accuracy in the dictionary
    accuracy_dict[epsilon] = overall_accuracy

# Print the accuracy for each epsilon
for epsilon, accuracy in accuracy_dict.items():
    print(f"Epsilon: {epsilon}, Accuracy: {accuracy}")

# Plot the accuracy for each epsilon
plt.figure(figsize=(10, 6))
plt.plot(list(accuracy_dict.keys()), list(accuracy_dict.values()), marker='o')
plt.xlabel('Epsilon')
plt.ylabel('Accuracy')
plt.title('Accuracy for different values of Epsilon')
plt.grid(True)
plt.show()

